{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with text data + Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "After this notebook you should know:\n",
    "\n",
    "* how to represent text data as features\n",
    "* how to evaluate your ML classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "<small>Tutorial adapted from scikit-learn. See [http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html)</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Recap ML 101: What we need\n",
    "\n",
    "1. Data\n",
    "  * input $X$ and output (labels) $Y$ \n",
    "2. Features\n",
    "  * the actual features: how $X$ is decomposed into its parts by the vectorizer/featurizer $\\phi$ --- **How do we extract features from text data?**\n",
    "3. Model/Algorithm\n",
    "  * the machine learning algorithm used \n",
    "4. Evaluation\n",
    "  * how to measure how good your model is --- **How do we evaluate our model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Extracting features from text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* IRIS example from last lecture: we were already given the features (do you remember how many those were?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* In NLP, we typically have many more features, and we typically first need to define **how to represent the text**.\n",
    "    * There is an extra step from the **raw text input** to the actual features that are used.\n",
    "    * This step of extracting features from raw (text) input is called **featurization** or **vectorization**\n",
    "\n",
    "    * It means that we turn the original content into a feature vector. Each dimension of the vector contains a numerical value and corresponds to a particular **feature**.\n",
    "    \n",
    "Let us look at a concrete example, the Reuters 20 newsgroup dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: Loading the 20 newsgroup dataset\n",
    "\n",
    "This notebook downloads the dataset automatically. Alternatively, it is possible to download the dataset manually (see how-to on the scikit-learn [tutorial website](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['soc.religion.christian', 'comp.graphics', 'sci.med']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train', categories=categories, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Notice: the data has been shuffled randomly, using a fixed seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'filenames', 'target_names', 'target', 'DESCR'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['comp.graphics', 'sci.med', 'soc.religion.christian']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Lets look at the first document (data instance) in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"From: tbrent@ecn.purdue.edu (Timothy J Brent)\\nSubject: Am I going to Hell?\\nOrganization: Purdue University Engineering Computer Network\\nLines: 12\\n\\nI have stated before that I do not consider myself an atheist, but \\ndefinitely do not believe in the christian god.  The recent discussion\\nabout atheists and hell, combined with a post to another group (to the\\neffect of 'you will all go to hell') has me interested in the consensus \\nas to how a god might judge men.  As a catholic, I was told that a jew,\\nbuddhist, etc. might go to heaven, but obviously some people do not\\nbelieve this.  Even more see atheists and pagans (I assume I would be \\nlumped into this category) to be hellbound.  I know you believe only\\ngod can judge, and I do not ask you to, just for your opinions.\\n\\nThanks,\\n-Tim\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train['data'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "What is $X$? \n",
    "\n",
    "The data ($X$) is still in raw (original) input format, no **featurizer** has yet been applied to the data. It is still an entire \"chunk\" of data (text in this case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "What are the $Y$s? \n",
    "\n",
    "As we saw already in the IRIS dataset, target (classes/labels/categories) are encoded as integers. These are the labels we are going to predict, they correspond to the `target_names` given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 0, ..., 0, 2, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We can get the original names back, lets say we want to look at the first 10 data instances and get their category/label:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "soc.religion.christian = 2\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "soc.religion.christian = 2\n",
      "comp.graphics = 0\n",
      "comp.graphics = 0\n",
      "sci.med = 1\n"
     ]
    }
   ],
   "source": [
    "for target_idx in twenty_train['target'][:10]:\n",
    "    print(twenty_train.target_names[target_idx], \"=\", target_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Extracting features from text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In order to run a machine learning algorithm, we first need to **transform** the original text data into a **set of features**.\n",
    "* This process is called featurization (or extracting features from data).\n",
    "* It goes from the raw input to a vector of some fixed size $d$, where each dimension of the vector corresponds to a particular **feature**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/learning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Bag-of-words \n",
    "\n",
    "A very simple way to decompose the input text is to make a 'bag-of-words' (BOW) representation.\n",
    "* The input text is broken down into single words\n",
    "* The feature vector encodes the words it has seen for a given instance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/bow1.png\" width=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For example, the following five instances would be represented in a BOW model as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/bow2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "**Note**: with BoW the sequence information is lost. E.g. the representations for \"boring just\" and \"just boring\" is the same.\n",
    "\n",
    "You can decide **which features** to include, maybe not always all words are good predictors for your target variable. For example, in the case of sentiment analysis we could decide to only use content words and punctuation (including emoticons) as features:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/bow3.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note, however, that typically the ML system does not store large feature vectors. In particular, when working with text data **most features in X will be zero**, i.e., only a few words actually occur in a particular instance/example. Storing the long vector would be very inefficient. Thus, internally sklearn keeps a **sparse** representation of the features. See more [here](http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html).\n",
    "\n",
    "What features to use is crucial for a machine learning system, and can make a big performance difference. This includes not only which tokens to keep but also whether to transform them in some way, e.g. lowercasing, stemming, lemmatization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Scikit-learn (sklearn) includes a range of built-in featurizers. We are only looking at a very simple vectorizer for count data, the `CountVectorizer`. But please have a look at more vectorizers available in sklearn/scikit-learn, like `TfIdfVectorizer`, or the custom `DictVectorizer`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The `CountVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 31638)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vectorizer = CountVectorizer().fit(twenty_train.data) #stop_words=\"english\"\n",
    "X_train_counts = count_vectorizer.transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1777"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x31638 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 93 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The `CountVectorizer` stores the data in **sparse** matrix format. It contains a `vocabulary` that maps features to their feature numbers. We can get the feature id (number) of a particular feature by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28369"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.vocabulary_.get(\"the\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The [`CountVectorizer`](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer) has many options. By default it stores the frequency of a word unigram (lowercased), where a word is defined by `token_pattern=u'(?u)\\b\\w\\w+\\b'`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, by storing the number of occurences of a token there is a side effect: longer documents will typically have higher average count values, even though they might talk about the same topic, say.  How can we avoid this issue?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Using **binary** (1/0 or on/off) feature values: instead of accounting for frequency, each token gets the same `weight`, it is either present or not. You can achieve binary (indicator) features by setting the `binary` option of the `CountVectorizer` to `binary=True`. \n",
    "\n",
    "2. Using **relative** term frequencies: instead of using the raw counts, divide by the total number of words in a document. Typically, you then want to downplay the importance of features that occur in many documents. This is achieved by weighting the frequency by the inverse document frequency (and hence, tokens that appear in many documents are less important). This is what the `TfIdfTokenizer` does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 31638)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using binary feature values\n",
    "count_vectorizer_binary = CountVectorizer(binary=True).fit(twenty_train.data)\n",
    "X_train_counts_binary = count_vectorizer_binary.transform(twenty_train.data)\n",
    "X_train_counts_binary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**A shortcut - `fit_transform`:** Note that the `sklearn` vectorizers have a shortcut `fit_transform`, this function does the two steps above in one go: `fit` creates the vocabulary from the data, then `transform` is used to convert the raw input data into feature vectors, given the vocabulary. Using `fit_transform` is at times faster.\n",
    "\n",
    "Note, however, that the `fit` function should always only be used on the training data -- otherwise you would create a new vocabulary on your test data and that would skrew things up. You *decide* your features on your training data, and test them then on your development/test data, you don't pick features based on the dev/test set!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Writing your own vectorizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "With the `DictVectorizer` you can add your own features, you have full control.\n",
    "As the name already says it wants a dictionary, where the keys are your feature names and  values are the feature values (binary or frequencies or what you want to use). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Now that we have converted our data into features, we can train our classifier to predict the category of a post. Let us try to use a logistic regression classifier, and use a binary word unigram BOW representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1777, 31638)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using binary feature values\n",
    "X_train = CountVectorizer(binary=True).fit_transform(twenty_train.data)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Now let's train the classifier and use it to predict the label of a new post. We again need to extract the features from the document, using the vectorizer. Then we can use the classifier to `predict` the label of the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "## train the classifier, and use it on a new document:\n",
    "clf.fit(X_train, twenty_train.target)\n",
    "document = [\"don't believe\"]\n",
    "X_test = count_vectorizer_binary.transform(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Note** the use of `tranform` here (**not** `fit_transform`). What would have happened if we were to call `fit_transform`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n",
      "soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "print(y_predicted)\n",
    "print(twenty_train.target_names[y_predicted[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Cool! We trained our classifier, using a BOW feature representation (with unigram word features as binary indicator values). In the example above we gave the classifier just a single new test instance. You can also give a list of examples to the classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "documents = [\"the graphic card sucks\", \"health / glucose is ..\", \"the right word\"]\n",
    "X_test = count_vectorizer_binary.transform(documents)\n",
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comp.graphics\n",
      "sci.med\n",
      "soc.religion.christian\n"
     ]
    }
   ],
   "source": [
    "for y_hat in y_predicted:\n",
    "    print(twenty_train.target_names[y_hat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Evaluating performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We want to build a classifier that generalizes (rather than memorizes), i.e., it works *beyond* the training data.\n",
    "\n",
    "A classifier generalizes reasonably well if it can predict with acceptable performance on new **unseen** test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "twenty_test = fetch_20newsgroups(subset='test', categories=categories, shuffle=True, random_state=42)\n",
    "## convert test to vectors\n",
    "X_test = count_vectorizer_binary.transform(twenty_test.data)\n",
    "y_predicted = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* **Accuracy**: out of all predictions, how many are correct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Evaluating accuracy is easy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9306846999154691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_true = twenty_test.target\n",
    "print(accuracy_score(y_true, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 93.07 (correct/total: 1101/1183.0)\n"
     ]
    }
   ],
   "source": [
    "# from scratch \n",
    "correct, total = 0, 0.0\n",
    "for gold, pred in zip(y_true,y_predicted):\n",
    "    if gold==pred:\n",
    "        correct+=1\n",
    "    total+=1\n",
    "print(\"Accuracy {0:.2f} (correct/total: {1}/{2})\".format(correct/total*100, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Or, alternatively, even easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9306846999154691"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.mean(y_true == y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "However, accuracy alone (= how many predictions are correct, out of all predictions) often tells us just part of the story. Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/accuracy.png\">\n",
    "\n",
    "$accuracy = \\frac{TP+TN}{TP+TN+FP+FN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "         comp.graphics       0.87      0.97      0.92       389\n",
      "               sci.med       0.97      0.84      0.90       396\n",
      "soc.religion.christian       0.96      0.99      0.98       398\n",
      "\n",
      "             micro avg       0.93      0.93      0.93      1183\n",
      "             macro avg       0.93      0.93      0.93      1183\n",
      "          weighted avg       0.93      0.93      0.93      1183\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# per-class breakdown\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_true, y_predicted,\n",
    "     target_names=twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Precision, Recall and F1:\n",
    "\n",
    "* **precision**: out of those predicted as a label, how many were correct\n",
    "* **recall**: how many instances, out of all instances of a specific label, did the classifier predict correctly\n",
    "* **f1-score**: harmonic mean of precision and recall (f1 has beta=1, i.e., both precision and recall are equally important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<img src=\"pics/precision_recall.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "From Wikipedia: <img src=\"https://upload.wikimedia.org/wikipedia/commons/2/26/Precisionrecall.svg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"pics/fscore.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "* pay attention when using accuracy if the categories are very skewed (one class that is much more frequent than others)\n",
    "* in such a case, how can you achieve high accuracy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluation - two data scenarios\n",
    "\n",
    "* Having a pre-split **train**/**dev**/**test** data: \n",
    "    * Build system using training data, use dev (development) data to find the right features, parameters, etc.\n",
    "    * Only at the very end evaluate your system on the final (held-out) test data\n",
    "    \n",
    "* **Cross-validation** / also called $k$-fold cross validation: split data into $k$ folds (parts), train a model on $k-1$ parts, evaluate on the last part; do this $k$ times and report final average (and std dev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Summary:\n",
    "\n",
    "* We have seen how to build a classifier with `sklearn` using word unigrams BOW features (exercise: examine the vectorizers of `sklearn`, try to use `DictVectorizer`)\n",
    "* Evaluation is important (how to measure performance - accuracy, precision, recall, f1 score; as well as how the evaluation is setup/evaluation scenario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "## Building a Pipeline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "In order to make the steps from input data to vectorizer to training a model easier, `sklearn` provides a `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "0.9306846999154691\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "#vectorizer = TfidfVectorizer()\n",
    "clf = LogisticRegression()\n",
    "classifier = Pipeline( [('vec', vectorizer),\n",
    "                        ('clf', clf)] )\n",
    "print(clf)\n",
    "classifier.fit(twenty_train.data, twenty_train.target)\n",
    "y_predicted = classifier.predict(twenty_test.data)\n",
    "print(accuracy_score(twenty_test.target, y_predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "* http://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "* http://scikit-learn.org/stable/modules/feature_extraction.html\n",
    "\n",
    "# Read More\n",
    "\n",
    "* Chapter 2 (pp. 29--38) of D. Rao and B. McMahan. 2019. NLP with PyTorch.\n",
    "* Chapters 6 and 7 (pp. 65--85) of Y. Goldberg. 2007. Neural Network Methods for NLP."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
